{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Into Machine Learning\n",
    "\n",
    "## 101 Training & Testing & Cross Validation\n",
    "\n",
    "数据集的处理至关重要，独立的测试集可以给算法进行评估，并且避免过度拟合的情况。\n",
    "\n",
    "### Features and Labels(特征和标签)\n",
    "\n",
    "特征是输入值，标签是输出值，我想要得到的算法就是可以输入数据特征，预测其可能的标签\n",
    "\n",
    "Features are individual measurable properties that you will be using to make predictions about your labels.\n",
    "\n",
    "### Train/Test split in sklearn\n",
    "\n",
    "首先，我学习如何将数据集分割成训练集和测试集。从库中自带的 datasets 中取一组数据作为研究"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]]\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "# df = pd.DataFrame(iris)\n",
    "print iris.data[:5]\n",
    "print iris.target[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这组数据的输入部分为 data 输出部分为 target\n",
    "\n",
    "每一个数据拥有四个特征，和一个标签，目的就是通过这四个特征，来预测其标签。\n",
    "\n",
    "接下来采用 cross_validation 中的 train_test_split 来分割数据集。 train_test_split 需要的内容有\n",
    "- 原始数据集的输入部分\n",
    "- 原始数据集的输出部分\n",
    "- 测试集占原始数据集的比例\n",
    "- 一个随机数种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90L, 4L), (60L, 4L))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=4)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我创建一个 SVM 的分类器对训练集进行分析并将得到的方法运用于测试集进行算法评价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过训练得到的 clf， 我可以对新的数据进行预测，比如："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\udacity\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array([ 5.1,3.5,2,0.2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，可以通过测试集对 clf 的预测结果进行评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98333333333333328"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validation(交叉验证)\n",
    "\n",
    "虽然我们分割了训练集和测试集，但是仍然存在过拟合的风险，所以采用cross validation(交叉验证)来避免风险。\n",
    "\n",
    "最简单的方法就是使用 cross_val_score 进行评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96666667,  1.        ,  0.96666667,  0.96666667,  1.        ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear',C=1) #创建一个空的分类器\n",
    "\n",
    "# 基于原始数据集对分类器进行五次交叉验证\n",
    "scores = cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到五次交叉验证的准确率，每次验证的评估方法默认采用 score method ，也可以进行指定，比如 f1_weighted method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96658312,  1.        ,  0.96658312,  0.96658312,  1.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score 中的 cv 为整数时，默认采用k-fold 或者 stratifiedkfold 进行交叉验证，我也可以自己定义交叉验证的划分方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97777778,  0.97777778,  1.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = iris.data.shape[0]\n",
    "cv = cross_validation.ShuffleSplit(n_samples, n_iter=3, test_size=0.3, random_state=0)\n",
    "cross_validation.cross_val_score(clf, iris.data, iris.target, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "为了让算法更加真实和精确，只对数据集进行交叉验证是不够的，对于一个算法，其中的参数也要进行不断的调整组合进行尝试。以SVM算法为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import grid_search\n",
    "parameters = {'kernel':('linear','rbf'),'C':[1,10]} # 指定变化的参数，这里是两种核函数和两个C值\n",
    "svc = svm.SVC() # 指定向量机算法\n",
    "clf = grid_search.GridSearchCV(svc, parameters) # 对上一步的算法中参数进行网格搜索\n",
    "clf.fit(iris.data,iris.target) # 采用网格搜索中所有参数组合的算法对数据进行拟合"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
