{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f749baeadd8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    normalized = (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    return normalized\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(np.max(x)+1)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = (None, *image_shape)\n",
    "    return tf.placeholder(tf.float32,shape,name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None, n_classes]\n",
    "    return tf.placeholder(tf.float32,shape,name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "#     channel = x_tensor.shape[1].value()\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w_1 = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], channel, conv_num_outputs], stddev=sd))\n",
    "    b_1 = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, w_1, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, b_1)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(\n",
    "        x_tensor,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w_2 = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=sd))\n",
    "    b_2 = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w_2), b_2)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "    channel = x_tensor.get_shape().as_list()[1]\n",
    "    w_3 = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=sd))\n",
    "    b_3 = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w_3), b_3)\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_num_outputs=(16,32,64)\n",
    "    conv_ksize=(3,3)\n",
    "    conv_strides=(1,1)\n",
    "    pool_ksize=(3,3)\n",
    "    pool_strides=(2,2)\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_1 = conv2d_maxpool(x, conv_num_outputs[0], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_2 = conv2d_maxpool(cvl_1, conv_num_outputs[1], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_3 = conv2d_maxpool(cvl_2, conv_num_outputs[2], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_layer = flatten(cvl_3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc_1 = fully_conn(flatten_layer,200)\n",
    "    fc_1 = tf.nn.dropout(fc_1, keep_prob)\n",
    "    \n",
    "    fc_2 = fully_conn(fc_1, 300)\n",
    "    fc_2 = tf.nn.dropout(fc_2, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(fc_2, num_outputs=10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    print('Loss: {:>10.5f} Validation Accuracy: {:.5f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.04800 Validation Accuracy: 0.30380\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.83580 Validation Accuracy: 0.38440\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.65305 Validation Accuracy: 0.43320\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.46938 Validation Accuracy: 0.46120\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    1.30972 Validation Accuracy: 0.47820\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    1.12078 Validation Accuracy: 0.49680\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    1.03059 Validation Accuracy: 0.50760\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.94887 Validation Accuracy: 0.50200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.79678 Validation Accuracy: 0.51760\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.70378 Validation Accuracy: 0.54420\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.66049 Validation Accuracy: 0.53140\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.58090 Validation Accuracy: 0.54540\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.57172 Validation Accuracy: 0.51620\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.46857 Validation Accuracy: 0.55360\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.37697 Validation Accuracy: 0.57380\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.33637 Validation Accuracy: 0.56040\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.29633 Validation Accuracy: 0.57120\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.28281 Validation Accuracy: 0.56680\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.20378 Validation Accuracy: 0.59540\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.18098 Validation Accuracy: 0.58540\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.16000 Validation Accuracy: 0.59380\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.14822 Validation Accuracy: 0.60280\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.12605 Validation Accuracy: 0.58280\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.11962 Validation Accuracy: 0.58420\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.11371 Validation Accuracy: 0.60360\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.11736 Validation Accuracy: 0.58560\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.15202 Validation Accuracy: 0.57940\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.12473 Validation Accuracy: 0.58860\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.08090 Validation Accuracy: 0.60020\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.06701 Validation Accuracy: 0.57780\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.07298 Validation Accuracy: 0.58720\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.10620 Validation Accuracy: 0.55820\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.11523 Validation Accuracy: 0.54720\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.06950 Validation Accuracy: 0.57080\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.05354 Validation Accuracy: 0.58780\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.04015 Validation Accuracy: 0.60220\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.02952 Validation Accuracy: 0.59760\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.04983 Validation Accuracy: 0.58900\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.07631 Validation Accuracy: 0.54000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.07969 Validation Accuracy: 0.58640\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.04830 Validation Accuracy: 0.58280\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.02712 Validation Accuracy: 0.57880\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.02002 Validation Accuracy: 0.59180\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.01616 Validation Accuracy: 0.60000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.01641 Validation Accuracy: 0.59180\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.01415 Validation Accuracy: 0.60360\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.01514 Validation Accuracy: 0.60260\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.01629 Validation Accuracy: 0.59960\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.01460 Validation Accuracy: 0.59660\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.01465 Validation Accuracy: 0.60760\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00842 Validation Accuracy: 0.61100\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.01621 Validation Accuracy: 0.60380\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.01092 Validation Accuracy: 0.59080\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.01031 Validation Accuracy: 0.60080\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00447 Validation Accuracy: 0.60320\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00606 Validation Accuracy: 0.60720\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.00333 Validation Accuracy: 0.60240\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00710 Validation Accuracy: 0.59940\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00806 Validation Accuracy: 0.58500\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.01118 Validation Accuracy: 0.58440\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00705 Validation Accuracy: 0.59140\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.00888 Validation Accuracy: 0.58640\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00401 Validation Accuracy: 0.58280\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.01278 Validation Accuracy: 0.57280\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00344 Validation Accuracy: 0.59420\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00236 Validation Accuracy: 0.59240\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00391 Validation Accuracy: 0.58500\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00381 Validation Accuracy: 0.57300\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00363 Validation Accuracy: 0.59160\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00534 Validation Accuracy: 0.57700\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00403 Validation Accuracy: 0.59540\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00085 Validation Accuracy: 0.60060\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00200 Validation Accuracy: 0.58860\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00118 Validation Accuracy: 0.58200\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00113 Validation Accuracy: 0.59720\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00140 Validation Accuracy: 0.58220\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00195 Validation Accuracy: 0.60100\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.00066 Validation Accuracy: 0.58580\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00181 Validation Accuracy: 0.58560\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00173 Validation Accuracy: 0.57920\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00184 Validation Accuracy: 0.58440\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00170 Validation Accuracy: 0.57620\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00207 Validation Accuracy: 0.58480\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00071 Validation Accuracy: 0.58960\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00063 Validation Accuracy: 0.58700\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00209 Validation Accuracy: 0.58740\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00159 Validation Accuracy: 0.60440\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00103 Validation Accuracy: 0.58940\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00111 Validation Accuracy: 0.60380\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00312 Validation Accuracy: 0.60600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00116 Validation Accuracy: 0.61200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00053 Validation Accuracy: 0.60260\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00142 Validation Accuracy: 0.60540\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00042 Validation Accuracy: 0.61160\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00215 Validation Accuracy: 0.60500\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00594 Validation Accuracy: 0.58800\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00097 Validation Accuracy: 0.60540\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00138 Validation Accuracy: 0.60440\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00052 Validation Accuracy: 0.59980\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00076 Validation Accuracy: 0.60600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.21041 Validation Accuracy: 0.24480\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:    1.84612 Validation Accuracy: 0.34180\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:    1.48010 Validation Accuracy: 0.40080\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:    1.45820 Validation Accuracy: 0.45460\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:    1.45588 Validation Accuracy: 0.46580\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.51597 Validation Accuracy: 0.49460\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:    1.29837 Validation Accuracy: 0.49520\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:    1.02548 Validation Accuracy: 0.50920\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:    1.07432 Validation Accuracy: 0.55400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:    1.11435 Validation Accuracy: 0.55720\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.16329 Validation Accuracy: 0.57220\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:    1.04173 Validation Accuracy: 0.56820\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:    0.74018 Validation Accuracy: 0.55300\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:    0.82937 Validation Accuracy: 0.60060\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:    0.95234 Validation Accuracy: 0.58340\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    0.92288 Validation Accuracy: 0.60440\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:    0.84825 Validation Accuracy: 0.60280\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:    0.56072 Validation Accuracy: 0.61400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:    0.65836 Validation Accuracy: 0.62340\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:    0.72149 Validation Accuracy: 0.60520\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    0.75106 Validation Accuracy: 0.61520\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:    0.70085 Validation Accuracy: 0.62960\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:    0.45954 Validation Accuracy: 0.61840\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:    0.59257 Validation Accuracy: 0.64060\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:    0.53712 Validation Accuracy: 0.63800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    0.66970 Validation Accuracy: 0.65320\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:    0.62959 Validation Accuracy: 0.65220\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:    0.38645 Validation Accuracy: 0.62460\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:    0.48323 Validation Accuracy: 0.65420\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:    0.48053 Validation Accuracy: 0.63420\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    0.54129 Validation Accuracy: 0.66660\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:    0.54297 Validation Accuracy: 0.65980\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:    0.30156 Validation Accuracy: 0.66360\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:    0.45328 Validation Accuracy: 0.67120\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:    0.40628 Validation Accuracy: 0.63300\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.48202 Validation Accuracy: 0.67320\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:    0.42924 Validation Accuracy: 0.67880\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:    0.26559 Validation Accuracy: 0.67100\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:    0.38169 Validation Accuracy: 0.67080\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:    0.29638 Validation Accuracy: 0.65660\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.38999 Validation Accuracy: 0.68000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:    0.35509 Validation Accuracy: 0.68800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:    0.21777 Validation Accuracy: 0.69280\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:    0.34768 Validation Accuracy: 0.68380\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:    0.25481 Validation Accuracy: 0.69980\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.33100 Validation Accuracy: 0.69300\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:    0.27056 Validation Accuracy: 0.70180\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:    0.21027 Validation Accuracy: 0.70000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:    0.29766 Validation Accuracy: 0.69260\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:    0.22818 Validation Accuracy: 0.69900\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.26556 Validation Accuracy: 0.68500\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:    0.26796 Validation Accuracy: 0.69120\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:    0.17779 Validation Accuracy: 0.68420\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:    0.22337 Validation Accuracy: 0.70060\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:    0.18688 Validation Accuracy: 0.70600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.26086 Validation Accuracy: 0.69860\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:    0.25671 Validation Accuracy: 0.70440\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:    0.14107 Validation Accuracy: 0.68780\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:    0.17692 Validation Accuracy: 0.71300\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:    0.15545 Validation Accuracy: 0.71360\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.20519 Validation Accuracy: 0.69520\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:    0.21161 Validation Accuracy: 0.69380\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:    0.13854 Validation Accuracy: 0.69380\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:    0.16564 Validation Accuracy: 0.70940\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:    0.13072 Validation Accuracy: 0.70820\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.19962 Validation Accuracy: 0.70380\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:    0.20210 Validation Accuracy: 0.67340\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:    0.13003 Validation Accuracy: 0.67280\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:    0.17886 Validation Accuracy: 0.71400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:    0.11237 Validation Accuracy: 0.71480\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.18421 Validation Accuracy: 0.69400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:    0.18166 Validation Accuracy: 0.68280\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:    0.11016 Validation Accuracy: 0.67980\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:    0.19930 Validation Accuracy: 0.69900\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:    0.09625 Validation Accuracy: 0.73180\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.20817 Validation Accuracy: 0.66940\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:    0.16217 Validation Accuracy: 0.70060\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:    0.11243 Validation Accuracy: 0.68700\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:    0.14312 Validation Accuracy: 0.71420\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:    0.09406 Validation Accuracy: 0.72440\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.15357 Validation Accuracy: 0.66840\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:    0.14382 Validation Accuracy: 0.70860\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:    0.07769 Validation Accuracy: 0.69160\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:    0.11548 Validation Accuracy: 0.71840\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:    0.08269 Validation Accuracy: 0.71840\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.10898 Validation Accuracy: 0.70060\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:    0.11423 Validation Accuracy: 0.68820\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:    0.10160 Validation Accuracy: 0.68300\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:    0.09356 Validation Accuracy: 0.71500\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:    0.05775 Validation Accuracy: 0.71860\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.11816 Validation Accuracy: 0.69420\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:    0.10220 Validation Accuracy: 0.70100\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:    0.06729 Validation Accuracy: 0.69500\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:    0.08110 Validation Accuracy: 0.72120\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:    0.05654 Validation Accuracy: 0.72140\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.08328 Validation Accuracy: 0.70500\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:    0.11834 Validation Accuracy: 0.70260\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:    0.03932 Validation Accuracy: 0.70760\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:    0.08784 Validation Accuracy: 0.71220\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:    0.04997 Validation Accuracy: 0.71760\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.07083 Validation Accuracy: 0.69740\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:    0.11442 Validation Accuracy: 0.70400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:    0.05947 Validation Accuracy: 0.71100\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:    0.07459 Validation Accuracy: 0.71380\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:    0.05563 Validation Accuracy: 0.71280\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.08765 Validation Accuracy: 0.70040\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:    0.08741 Validation Accuracy: 0.71120\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:    0.05118 Validation Accuracy: 0.71480\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:    0.06337 Validation Accuracy: 0.70960\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:    0.04774 Validation Accuracy: 0.69780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.06561 Validation Accuracy: 0.70880\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:    0.09787 Validation Accuracy: 0.70780\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:    0.04033 Validation Accuracy: 0.72200\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:    0.07569 Validation Accuracy: 0.70360\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:    0.03766 Validation Accuracy: 0.70440\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.05026 Validation Accuracy: 0.71340\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:    0.08039 Validation Accuracy: 0.71380\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:    0.02807 Validation Accuracy: 0.71860\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:    0.05486 Validation Accuracy: 0.70980\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:    0.02989 Validation Accuracy: 0.70280\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.04775 Validation Accuracy: 0.71820\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:    0.07453 Validation Accuracy: 0.71920\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:    0.03176 Validation Accuracy: 0.71540\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:    0.04932 Validation Accuracy: 0.71060\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:    0.02854 Validation Accuracy: 0.71560\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.05034 Validation Accuracy: 0.70780\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:    0.05072 Validation Accuracy: 0.71340\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:    0.03334 Validation Accuracy: 0.71740\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:    0.05303 Validation Accuracy: 0.70100\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:    0.02951 Validation Accuracy: 0.70220\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.04183 Validation Accuracy: 0.70760\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:    0.05658 Validation Accuracy: 0.68880\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:    0.02442 Validation Accuracy: 0.72420\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:    0.03329 Validation Accuracy: 0.69900\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:    0.03256 Validation Accuracy: 0.68800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.03889 Validation Accuracy: 0.71640\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:    0.03545 Validation Accuracy: 0.70720\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:    0.02322 Validation Accuracy: 0.72160\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:    0.03956 Validation Accuracy: 0.69660\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:    0.02737 Validation Accuracy: 0.70320\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.02465 Validation Accuracy: 0.71260\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:    0.03076 Validation Accuracy: 0.70100\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:    0.02749 Validation Accuracy: 0.70580\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:    0.05555 Validation Accuracy: 0.70820\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:    0.02988 Validation Accuracy: 0.69000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.03593 Validation Accuracy: 0.71200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:    0.03737 Validation Accuracy: 0.69780\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:    0.01911 Validation Accuracy: 0.72060\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:    0.02172 Validation Accuracy: 0.70820\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:    0.01934 Validation Accuracy: 0.70060\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.02444 Validation Accuracy: 0.71040\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:    0.03332 Validation Accuracy: 0.68980\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:    0.03033 Validation Accuracy: 0.71500\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:    0.02026 Validation Accuracy: 0.70640\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:    0.02500 Validation Accuracy: 0.70760\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.02477 Validation Accuracy: 0.70720\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:    0.02405 Validation Accuracy: 0.70120\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:    0.02850 Validation Accuracy: 0.69880\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:    0.03243 Validation Accuracy: 0.71500\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:    0.01651 Validation Accuracy: 0.70960\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.02953 Validation Accuracy: 0.70820\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:    0.02405 Validation Accuracy: 0.70800\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:    0.02118 Validation Accuracy: 0.71840\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:    0.02883 Validation Accuracy: 0.70460\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:    0.01425 Validation Accuracy: 0.71240\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.03182 Validation Accuracy: 0.70300\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:    0.03404 Validation Accuracy: 0.70740\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:    0.02236 Validation Accuracy: 0.70400\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:    0.01601 Validation Accuracy: 0.70660\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:    0.01959 Validation Accuracy: 0.70580\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.02213 Validation Accuracy: 0.70820\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:    0.02630 Validation Accuracy: 0.69080\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:    0.01432 Validation Accuracy: 0.72280\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:    0.03158 Validation Accuracy: 0.71240\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:    0.03301 Validation Accuracy: 0.70300\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.02927 Validation Accuracy: 0.70920\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:    0.02531 Validation Accuracy: 0.69040\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:    0.01764 Validation Accuracy: 0.70820\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:    0.02156 Validation Accuracy: 0.71140\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:    0.02407 Validation Accuracy: 0.71040\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.04271 Validation Accuracy: 0.68700\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:    0.02575 Validation Accuracy: 0.70060\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:    0.01700 Validation Accuracy: 0.71380\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:    0.02096 Validation Accuracy: 0.70400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:    0.00714 Validation Accuracy: 0.70880\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.02651 Validation Accuracy: 0.68740\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:    0.04235 Validation Accuracy: 0.71200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:    0.01457 Validation Accuracy: 0.71980\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:    0.01729 Validation Accuracy: 0.70460\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:    0.01258 Validation Accuracy: 0.70620\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.01853 Validation Accuracy: 0.68840\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:    0.02191 Validation Accuracy: 0.69460\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:    0.02172 Validation Accuracy: 0.71480\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:    0.02069 Validation Accuracy: 0.70880\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:    0.01159 Validation Accuracy: 0.68900\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.01424 Validation Accuracy: 0.70500\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:    0.03002 Validation Accuracy: 0.69260\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:    0.01184 Validation Accuracy: 0.72040\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:    0.01938 Validation Accuracy: 0.70740\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:    0.00761 Validation Accuracy: 0.70660\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.02046 Validation Accuracy: 0.70020\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:    0.02036 Validation Accuracy: 0.68900\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:    0.01739 Validation Accuracy: 0.71860\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:    0.02846 Validation Accuracy: 0.70520\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:    0.01027 Validation Accuracy: 0.70880\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.01677 Validation Accuracy: 0.70160\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:    0.01380 Validation Accuracy: 0.70500\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:    0.02100 Validation Accuracy: 0.71620\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:    0.01912 Validation Accuracy: 0.69540\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:    0.01383 Validation Accuracy: 0.70360\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.01293 Validation Accuracy: 0.69480\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:    0.01477 Validation Accuracy: 0.70860\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:    0.00994 Validation Accuracy: 0.71640\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:    0.01526 Validation Accuracy: 0.68620\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:    0.01006 Validation Accuracy: 0.70820\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.02271 Validation Accuracy: 0.69900\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:    0.00846 Validation Accuracy: 0.69880\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:    0.02065 Validation Accuracy: 0.71140\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:    0.01318 Validation Accuracy: 0.69520\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:    0.01847 Validation Accuracy: 0.70840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.01456 Validation Accuracy: 0.70620\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:    0.00866 Validation Accuracy: 0.70720\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:    0.01905 Validation Accuracy: 0.71980\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:    0.01199 Validation Accuracy: 0.69060\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:    0.01041 Validation Accuracy: 0.70880\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.01024 Validation Accuracy: 0.70400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:    0.01458 Validation Accuracy: 0.70420\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:    0.01016 Validation Accuracy: 0.71640\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:    0.02143 Validation Accuracy: 0.69520\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:    0.00544 Validation Accuracy: 0.72540\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.00946 Validation Accuracy: 0.70280\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:    0.00559 Validation Accuracy: 0.70520\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:    0.01011 Validation Accuracy: 0.71540\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:    0.00647 Validation Accuracy: 0.69880\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:    0.00708 Validation Accuracy: 0.71700\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.00916 Validation Accuracy: 0.69420\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:    0.00720 Validation Accuracy: 0.70660\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:    0.00614 Validation Accuracy: 0.71080\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:    0.00737 Validation Accuracy: 0.69480\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:    0.00530 Validation Accuracy: 0.70860\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.00827 Validation Accuracy: 0.71760\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:    0.00311 Validation Accuracy: 0.71400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:    0.00473 Validation Accuracy: 0.71320\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:    0.00897 Validation Accuracy: 0.70000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:    0.00585 Validation Accuracy: 0.70700\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.00600 Validation Accuracy: 0.70340\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:    0.00842 Validation Accuracy: 0.70840\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:    0.00653 Validation Accuracy: 0.70680\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:    0.01208 Validation Accuracy: 0.70720\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:    0.01157 Validation Accuracy: 0.71040\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00580 Validation Accuracy: 0.70560\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:    0.01489 Validation Accuracy: 0.70420\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:    0.00526 Validation Accuracy: 0.71900\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:    0.01353 Validation Accuracy: 0.69080\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:    0.01505 Validation Accuracy: 0.71260\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.00559 Validation Accuracy: 0.69560\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:    0.00631 Validation Accuracy: 0.70480\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:    0.00830 Validation Accuracy: 0.71660\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:    0.02089 Validation Accuracy: 0.68340\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:    0.00896 Validation Accuracy: 0.72100\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.00626 Validation Accuracy: 0.70360\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:    0.00566 Validation Accuracy: 0.70860\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:    0.00755 Validation Accuracy: 0.71920\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:    0.02031 Validation Accuracy: 0.68200\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:    0.01055 Validation Accuracy: 0.70720\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.01777 Validation Accuracy: 0.69460\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:    0.00579 Validation Accuracy: 0.70480\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:    0.01343 Validation Accuracy: 0.70540\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:    0.01975 Validation Accuracy: 0.68860\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:    0.00873 Validation Accuracy: 0.70560\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00571 Validation Accuracy: 0.69820\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:    0.00842 Validation Accuracy: 0.70340\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:    0.00761 Validation Accuracy: 0.71400\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:    0.01309 Validation Accuracy: 0.68720\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:    0.00884 Validation Accuracy: 0.70720\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00733 Validation Accuracy: 0.69740\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:    0.02474 Validation Accuracy: 0.70480\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:    0.00796 Validation Accuracy: 0.71660\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:    0.01222 Validation Accuracy: 0.69120\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:    0.00941 Validation Accuracy: 0.70100\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.01075 Validation Accuracy: 0.69900\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:    0.00657 Validation Accuracy: 0.69820\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:    0.00555 Validation Accuracy: 0.71680\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:    0.00799 Validation Accuracy: 0.70520\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:    0.00850 Validation Accuracy: 0.70160\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00556 Validation Accuracy: 0.70980\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:    0.00387 Validation Accuracy: 0.71280\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:    0.00966 Validation Accuracy: 0.71520\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:    0.00810 Validation Accuracy: 0.70220\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:    0.00853 Validation Accuracy: 0.70200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00887 Validation Accuracy: 0.71060\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:    0.00874 Validation Accuracy: 0.70720\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:    0.00304 Validation Accuracy: 0.72220\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:    0.00810 Validation Accuracy: 0.69600\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:    0.00717 Validation Accuracy: 0.69740\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.00962 Validation Accuracy: 0.69500\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:    0.00176 Validation Accuracy: 0.70720\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:    0.00276 Validation Accuracy: 0.72300\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:    0.01412 Validation Accuracy: 0.70000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:    0.00305 Validation Accuracy: 0.70440\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00405 Validation Accuracy: 0.69360\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:    0.01359 Validation Accuracy: 0.70380\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:    0.00802 Validation Accuracy: 0.71360\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:    0.00821 Validation Accuracy: 0.69900\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:    0.00283 Validation Accuracy: 0.70440\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.01719 Validation Accuracy: 0.68580\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:    0.00398 Validation Accuracy: 0.70400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:    0.00228 Validation Accuracy: 0.71400\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:    0.00939 Validation Accuracy: 0.69940\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:    0.00374 Validation Accuracy: 0.71020\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00944 Validation Accuracy: 0.70400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:    0.00226 Validation Accuracy: 0.70020\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:    0.00293 Validation Accuracy: 0.71600\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:    0.00574 Validation Accuracy: 0.69200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:    0.00655 Validation Accuracy: 0.70040\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.01135 Validation Accuracy: 0.69900\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:    0.00502 Validation Accuracy: 0.69800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:    0.00243 Validation Accuracy: 0.71560\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:    0.00708 Validation Accuracy: 0.68480\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:    0.00560 Validation Accuracy: 0.70480\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00494 Validation Accuracy: 0.69800\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:    0.00131 Validation Accuracy: 0.70560\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:    0.00105 Validation Accuracy: 0.71960\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:    0.00406 Validation Accuracy: 0.69360\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:    0.00611 Validation Accuracy: 0.69900\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00861 Validation Accuracy: 0.69320\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:    0.00845 Validation Accuracy: 0.69060\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:    0.00697 Validation Accuracy: 0.71440\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:    0.00330 Validation Accuracy: 0.70060\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:    0.00243 Validation Accuracy: 0.69820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00548 Validation Accuracy: 0.70860\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:    0.00386 Validation Accuracy: 0.69000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:    0.00185 Validation Accuracy: 0.71020\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:    0.00771 Validation Accuracy: 0.70680\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:    0.00399 Validation Accuracy: 0.70600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00927 Validation Accuracy: 0.70300\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:    0.00700 Validation Accuracy: 0.69300\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:    0.00766 Validation Accuracy: 0.71120\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:    0.00353 Validation Accuracy: 0.70520\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:    0.00891 Validation Accuracy: 0.70380\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00358 Validation Accuracy: 0.71600\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:    0.00256 Validation Accuracy: 0.69780\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:    0.01526 Validation Accuracy: 0.70940\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:    0.00482 Validation Accuracy: 0.69620\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:    0.00317 Validation Accuracy: 0.70260\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00849 Validation Accuracy: 0.70300\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:    0.00282 Validation Accuracy: 0.69340\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:    0.00154 Validation Accuracy: 0.72020\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:    0.00499 Validation Accuracy: 0.69000\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:    0.00449 Validation Accuracy: 0.71340\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00808 Validation Accuracy: 0.69600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:    0.01337 Validation Accuracy: 0.69800\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:    0.01304 Validation Accuracy: 0.71700\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:    0.01763 Validation Accuracy: 0.71380\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:    0.00398 Validation Accuracy: 0.70820\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00432 Validation Accuracy: 0.69960\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:    0.00718 Validation Accuracy: 0.69580\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:    0.00209 Validation Accuracy: 0.71480\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:    0.00893 Validation Accuracy: 0.70760\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:    0.00337 Validation Accuracy: 0.71620\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00323 Validation Accuracy: 0.71380\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:    0.00174 Validation Accuracy: 0.70060\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:    0.00224 Validation Accuracy: 0.71140\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:    0.00562 Validation Accuracy: 0.70180\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:    0.00124 Validation Accuracy: 0.71900\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00484 Validation Accuracy: 0.70540\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:    0.00306 Validation Accuracy: 0.69560\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:    0.00376 Validation Accuracy: 0.71420\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:    0.00288 Validation Accuracy: 0.70040\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:    0.00307 Validation Accuracy: 0.72500\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00459 Validation Accuracy: 0.71600\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:    0.00295 Validation Accuracy: 0.69440\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:    0.00565 Validation Accuracy: 0.71500\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:    0.00430 Validation Accuracy: 0.70280\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:    0.00116 Validation Accuracy: 0.71640\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00487 Validation Accuracy: 0.71500\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:    0.00106 Validation Accuracy: 0.70740\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:    0.00109 Validation Accuracy: 0.71240\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:    0.00399 Validation Accuracy: 0.69720\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:    0.00378 Validation Accuracy: 0.71660\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00127 Validation Accuracy: 0.71240\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:    0.00540 Validation Accuracy: 0.70860\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:    0.00202 Validation Accuracy: 0.71660\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:    0.00323 Validation Accuracy: 0.69800\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:    0.00169 Validation Accuracy: 0.71680\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.01007 Validation Accuracy: 0.70920\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:    0.00225 Validation Accuracy: 0.70600\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:    0.00055 Validation Accuracy: 0.70640\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:    0.00320 Validation Accuracy: 0.69860\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:    0.00102 Validation Accuracy: 0.70980\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00239 Validation Accuracy: 0.71940\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:    0.00189 Validation Accuracy: 0.70560\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:    0.00070 Validation Accuracy: 0.72040\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:    0.00186 Validation Accuracy: 0.69260\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:    0.00098 Validation Accuracy: 0.72620\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00376 Validation Accuracy: 0.71280\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:    0.00116 Validation Accuracy: 0.70020\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:    0.00147 Validation Accuracy: 0.71340\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:    0.00356 Validation Accuracy: 0.69820\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:    0.00138 Validation Accuracy: 0.70960\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00551 Validation Accuracy: 0.72100\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:    0.00179 Validation Accuracy: 0.71260\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:    0.00053 Validation Accuracy: 0.71400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:    0.00508 Validation Accuracy: 0.69740\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:    0.00105 Validation Accuracy: 0.71580\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00478 Validation Accuracy: 0.71140\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:    0.00093 Validation Accuracy: 0.70720\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:    0.00156 Validation Accuracy: 0.72040\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:    0.00297 Validation Accuracy: 0.70340\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:    0.00215 Validation Accuracy: 0.70480\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00271 Validation Accuracy: 0.71800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:    0.00064 Validation Accuracy: 0.71280\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:    0.00027 Validation Accuracy: 0.71820\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:    0.00509 Validation Accuracy: 0.70240\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:    0.00196 Validation Accuracy: 0.70580\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00451 Validation Accuracy: 0.71220\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:    0.00119 Validation Accuracy: 0.70740\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:    0.00139 Validation Accuracy: 0.71420\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:    0.00530 Validation Accuracy: 0.69960\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:    0.00531 Validation Accuracy: 0.69620\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00182 Validation Accuracy: 0.72000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:    0.00370 Validation Accuracy: 0.71420\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:    0.00030 Validation Accuracy: 0.71540\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:    0.00317 Validation Accuracy: 0.69440\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:    0.00213 Validation Accuracy: 0.71400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00256 Validation Accuracy: 0.71840\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:    0.00099 Validation Accuracy: 0.72060\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:    0.00057 Validation Accuracy: 0.71820\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:    0.00415 Validation Accuracy: 0.69140\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:    0.00064 Validation Accuracy: 0.71400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00192 Validation Accuracy: 0.71580\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:    0.00214 Validation Accuracy: 0.70600\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:    0.00067 Validation Accuracy: 0.71680\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:    0.00509 Validation Accuracy: 0.69440\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:    0.00325 Validation Accuracy: 0.70880\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00353 Validation Accuracy: 0.72140\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:    0.00178 Validation Accuracy: 0.71140\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:    0.00034 Validation Accuracy: 0.72040\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:    0.00345 Validation Accuracy: 0.70360\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:    0.00187 Validation Accuracy: 0.70940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00325 Validation Accuracy: 0.72080\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:    0.00120 Validation Accuracy: 0.71260\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:    0.00120 Validation Accuracy: 0.71980\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:    0.00345 Validation Accuracy: 0.69780\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:    0.01367 Validation Accuracy: 0.71440\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00523 Validation Accuracy: 0.71780\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:    0.00308 Validation Accuracy: 0.71420\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:    0.00041 Validation Accuracy: 0.71520\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:    0.00572 Validation Accuracy: 0.69620\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:    0.00236 Validation Accuracy: 0.70780\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00392 Validation Accuracy: 0.72120\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:    0.00104 Validation Accuracy: 0.71640\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:    0.00035 Validation Accuracy: 0.72300\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:    0.00125 Validation Accuracy: 0.70020\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:    0.00116 Validation Accuracy: 0.71280\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00151 Validation Accuracy: 0.72320\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:    0.00275 Validation Accuracy: 0.71800\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:    0.00131 Validation Accuracy: 0.71960\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:    0.00067 Validation Accuracy: 0.71160\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:    0.00106 Validation Accuracy: 0.72360\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00088 Validation Accuracy: 0.72700\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:    0.00144 Validation Accuracy: 0.71700\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:    0.00133 Validation Accuracy: 0.71620\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:    0.00946 Validation Accuracy: 0.70600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:    0.00087 Validation Accuracy: 0.71820\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00392 Validation Accuracy: 0.71860\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:    0.00143 Validation Accuracy: 0.72480\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:    0.00113 Validation Accuracy: 0.71520\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:    0.00405 Validation Accuracy: 0.70460\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:    0.00336 Validation Accuracy: 0.70780\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00165 Validation Accuracy: 0.71760\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:    0.00089 Validation Accuracy: 0.71180\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:    0.00044 Validation Accuracy: 0.71500\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:    0.00163 Validation Accuracy: 0.70840\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:    0.00085 Validation Accuracy: 0.70840\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00064 Validation Accuracy: 0.72320\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:    0.00157 Validation Accuracy: 0.71700\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:    0.00017 Validation Accuracy: 0.71600\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:    0.00925 Validation Accuracy: 0.71120\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:    0.00060 Validation Accuracy: 0.71520\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00193 Validation Accuracy: 0.72300\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:    0.00155 Validation Accuracy: 0.70980\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:    0.00037 Validation Accuracy: 0.71740\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:    0.00387 Validation Accuracy: 0.70900\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:    0.00046 Validation Accuracy: 0.72080\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00103 Validation Accuracy: 0.72000\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:    0.00073 Validation Accuracy: 0.71980\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:    0.00013 Validation Accuracy: 0.72180\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:    0.00170 Validation Accuracy: 0.69520\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:    0.00114 Validation Accuracy: 0.70940\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00081 Validation Accuracy: 0.72460\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:    0.00032 Validation Accuracy: 0.71360\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    0.00025 Validation Accuracy: 0.71180\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:    0.00294 Validation Accuracy: 0.70380\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:    0.00076 Validation Accuracy: 0.71140\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00161 Validation Accuracy: 0.72120\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:    0.00675 Validation Accuracy: 0.71220\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:    0.00026 Validation Accuracy: 0.71580\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:    0.00109 Validation Accuracy: 0.70680\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:    0.00214 Validation Accuracy: 0.71460\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7140510141849518\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzMzs+z/Az+eOrM4u51rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7480105a58>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "#     test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    test_features, test_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
