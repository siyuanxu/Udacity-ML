{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f749baeadd8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    normalized = (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    return normalized\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(np.max(x)+1)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = (None, *image_shape)\n",
    "    return tf.placeholder(tf.float32,shape,name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = [None, n_classes]\n",
    "    return tf.placeholder(tf.float32,shape,name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, None, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "#     channel = x_tensor.shape[1].value()\n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w_1 = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1], channel, conv_num_outputs], stddev=sd))\n",
    "    b_1 = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, w_1, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, b_1)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    x_tensor = tf.nn.max_pool(\n",
    "        x_tensor,\n",
    "        ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "        strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "        padding='SAME')\n",
    "\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.contrib.layers.flatten(x_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "    channel = x_tensor.get_shape().as_list()[-1]\n",
    "    w_2 = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=sd))\n",
    "    b_2 = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w_2), b_2)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    sd = 0.1\n",
    "    \n",
    "    channel = x_tensor.get_shape().as_list()[1]\n",
    "    w_3 = tf.Variable(tf.truncated_normal([channel, num_outputs], stddev=sd))\n",
    "    b_3 = tf.Variable(tf.zeros([num_outputs]))\n",
    "    x_tensor = tf.add(tf.matmul(x_tensor, w_3), b_3)\n",
    "    \n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    \n",
    "    conv_num_outputs=(16,32,64)\n",
    "    conv_ksize=(3,3)\n",
    "    conv_strides=(1,1)\n",
    "    pool_ksize=(3,3)\n",
    "    pool_strides=(2,2)\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_1 = conv2d_maxpool(x, conv_num_outputs[0], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_2 = conv2d_maxpool(cvl_1, conv_num_outputs[1], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    cvl_3 = conv2d_maxpool(cvl_2, conv_num_outputs[2], conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_layer = flatten(cvl_3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc_1 = fully_conn(flatten_layer,200)\n",
    "    fc_1 = tf.nn.dropout(fc_1, keep_prob)\n",
    "    \n",
    "    fc_2 = fully_conn(fc_1, 300)\n",
    "    fc_2 = tf.nn.dropout(fc_2, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output(fc_2, num_outputs=10)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.})\n",
    "    print('Loss: {:>10.5f} Validation Accuracy: {:.5f}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 256\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.04800 Validation Accuracy: 0.30380\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.83580 Validation Accuracy: 0.38440\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.65305 Validation Accuracy: 0.43320\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    1.46938 Validation Accuracy: 0.46120\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    1.30972 Validation Accuracy: 0.47820\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    1.12078 Validation Accuracy: 0.49680\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    1.03059 Validation Accuracy: 0.50760\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.94887 Validation Accuracy: 0.50200\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.79678 Validation Accuracy: 0.51760\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.70378 Validation Accuracy: 0.54420\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.66049 Validation Accuracy: 0.53140\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.58090 Validation Accuracy: 0.54540\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.57172 Validation Accuracy: 0.51620\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.46857 Validation Accuracy: 0.55360\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.37697 Validation Accuracy: 0.57380\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.33637 Validation Accuracy: 0.56040\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.29633 Validation Accuracy: 0.57120\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.28281 Validation Accuracy: 0.56680\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.20378 Validation Accuracy: 0.59540\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.18098 Validation Accuracy: 0.58540\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.16000 Validation Accuracy: 0.59380\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.14822 Validation Accuracy: 0.60280\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.12605 Validation Accuracy: 0.58280\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.11962 Validation Accuracy: 0.58420\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.11371 Validation Accuracy: 0.60360\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.11736 Validation Accuracy: 0.58560\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.15202 Validation Accuracy: 0.57940\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.12473 Validation Accuracy: 0.58860\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.08090 Validation Accuracy: 0.60020\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.06701 Validation Accuracy: 0.57780\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.07298 Validation Accuracy: 0.58720\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.10620 Validation Accuracy: 0.55820\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.11523 Validation Accuracy: 0.54720\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.06950 Validation Accuracy: 0.57080\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.05354 Validation Accuracy: 0.58780\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.04015 Validation Accuracy: 0.60220\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.02952 Validation Accuracy: 0.59760\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.04983 Validation Accuracy: 0.58900\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.07631 Validation Accuracy: 0.54000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.07969 Validation Accuracy: 0.58640\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.04830 Validation Accuracy: 0.58280\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.02712 Validation Accuracy: 0.57880\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.02002 Validation Accuracy: 0.59180\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.01616 Validation Accuracy: 0.60000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.01641 Validation Accuracy: 0.59180\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.01415 Validation Accuracy: 0.60360\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.01514 Validation Accuracy: 0.60260\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.01629 Validation Accuracy: 0.59960\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.01460 Validation Accuracy: 0.59660\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.01465 Validation Accuracy: 0.60760\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00842 Validation Accuracy: 0.61100\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.01621 Validation Accuracy: 0.60380\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.01092 Validation Accuracy: 0.59080\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.01031 Validation Accuracy: 0.60080\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00447 Validation Accuracy: 0.60320\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00606 Validation Accuracy: 0.60720\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.00333 Validation Accuracy: 0.60240\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00710 Validation Accuracy: 0.59940\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00806 Validation Accuracy: 0.58500\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.01118 Validation Accuracy: 0.58440\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00705 Validation Accuracy: 0.59140\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.00888 Validation Accuracy: 0.58640\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00401 Validation Accuracy: 0.58280\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.01278 Validation Accuracy: 0.57280\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00344 Validation Accuracy: 0.59420\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00236 Validation Accuracy: 0.59240\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00391 Validation Accuracy: 0.58500\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00381 Validation Accuracy: 0.57300\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00363 Validation Accuracy: 0.59160\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00534 Validation Accuracy: 0.57700\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00403 Validation Accuracy: 0.59540\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00085 Validation Accuracy: 0.60060\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00200 Validation Accuracy: 0.58860\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00118 Validation Accuracy: 0.58200\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00113 Validation Accuracy: 0.59720\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00140 Validation Accuracy: 0.58220\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00195 Validation Accuracy: 0.60100\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.00066 Validation Accuracy: 0.58580\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00181 Validation Accuracy: 0.58560\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00173 Validation Accuracy: 0.57920\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00184 Validation Accuracy: 0.58440\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00170 Validation Accuracy: 0.57620\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00207 Validation Accuracy: 0.58480\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00071 Validation Accuracy: 0.58960\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00063 Validation Accuracy: 0.58700\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00209 Validation Accuracy: 0.58740\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00159 Validation Accuracy: 0.60440\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00103 Validation Accuracy: 0.58940\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00111 Validation Accuracy: 0.60380\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00312 Validation Accuracy: 0.60600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00116 Validation Accuracy: 0.61200\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00053 Validation Accuracy: 0.60260\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00142 Validation Accuracy: 0.60540\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00042 Validation Accuracy: 0.61160\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00215 Validation Accuracy: 0.60500\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00594 Validation Accuracy: 0.58800\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00097 Validation Accuracy: 0.60540\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00138 Validation Accuracy: 0.60440\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00052 Validation Accuracy: 0.59980\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00076 Validation Accuracy: 0.60600\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:    2.21041 Validation Accuracy: 0.24480\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:    1.84612 Validation Accuracy: 0.34180\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:    1.48010 Validation Accuracy: 0.40080\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:    1.45820 Validation Accuracy: 0.45460\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:    1.45588 Validation Accuracy: 0.46580\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:    1.51597 Validation Accuracy: 0.49460\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:    1.29837 Validation Accuracy: 0.49520\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:    1.02548 Validation Accuracy: 0.50920\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:    1.07432 Validation Accuracy: 0.55400\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:    1.11435 Validation Accuracy: 0.55720\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:    1.16329 Validation Accuracy: 0.57220\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:    1.04173 Validation Accuracy: 0.56820\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:    0.74018 Validation Accuracy: 0.55300\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:    0.82937 Validation Accuracy: 0.60060\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:    0.95234 Validation Accuracy: 0.58340\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:    0.92288 Validation Accuracy: 0.60440\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:    0.84825 Validation Accuracy: 0.60280\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:    0.56072 Validation Accuracy: 0.61400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:    0.65836 Validation Accuracy: 0.62340\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:    0.72149 Validation Accuracy: 0.60520\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:    0.75106 Validation Accuracy: 0.61520\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:    0.70085 Validation Accuracy: 0.62960\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:    0.45954 Validation Accuracy: 0.61840\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:    0.59257 Validation Accuracy: 0.64060\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:    0.53712 Validation Accuracy: 0.63800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:    0.66970 Validation Accuracy: 0.65320\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:    0.62959 Validation Accuracy: 0.65220\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:    0.38645 Validation Accuracy: 0.62460\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:    0.48323 Validation Accuracy: 0.65420\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:    0.48053 Validation Accuracy: 0.63420\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:    0.54129 Validation Accuracy: 0.66660\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:    0.54297 Validation Accuracy: 0.65980\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:    0.30156 Validation Accuracy: 0.66360\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:    0.45328 Validation Accuracy: 0.67120\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:    0.40628 Validation Accuracy: 0.63300\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:    0.48202 Validation Accuracy: 0.67320\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:    0.42924 Validation Accuracy: 0.67880\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:    0.26559 Validation Accuracy: 0.67100\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:    0.38169 Validation Accuracy: 0.67080\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:    0.29638 Validation Accuracy: 0.65660\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:    0.38999 Validation Accuracy: 0.68000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:    0.35509 Validation Accuracy: 0.68800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:    0.21777 Validation Accuracy: 0.69280\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:    0.34768 Validation Accuracy: 0.68380\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:    0.25481 Validation Accuracy: 0.69980\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:    0.33100 Validation Accuracy: 0.69300\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:    0.27056 Validation Accuracy: 0.70180\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:    0.21027 Validation Accuracy: 0.70000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:    0.29766 Validation Accuracy: 0.69260\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:    0.22818 Validation Accuracy: 0.69900\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:    0.26556 Validation Accuracy: 0.68500\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:    0.26796 Validation Accuracy: 0.69120\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:    0.17779 Validation Accuracy: 0.68420\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:    0.22337 Validation Accuracy: 0.70060\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:    0.18688 Validation Accuracy: 0.70600\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:    0.26086 Validation Accuracy: 0.69860\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:    0.25671 Validation Accuracy: 0.70440\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:    0.14107 Validation Accuracy: 0.68780\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:    0.17692 Validation Accuracy: 0.71300\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:    0.15545 Validation Accuracy: 0.71360\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:    0.20519 Validation Accuracy: 0.69520\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:    0.21161 Validation Accuracy: 0.69380\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:    0.13854 Validation Accuracy: 0.69380\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:    0.16564 Validation Accuracy: 0.70940\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:    0.13072 Validation Accuracy: 0.70820\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:    0.19962 Validation Accuracy: 0.70380\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:    0.20210 Validation Accuracy: 0.67340\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:    0.13003 Validation Accuracy: 0.67280\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:    0.17886 Validation Accuracy: 0.71400\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:    0.11237 Validation Accuracy: 0.71480\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:    0.18421 Validation Accuracy: 0.69400\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:    0.18166 Validation Accuracy: 0.68280\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:    0.11016 Validation Accuracy: 0.67980\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:    0.19930 Validation Accuracy: 0.69900\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:    0.09625 Validation Accuracy: 0.73180\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:    0.20817 Validation Accuracy: 0.66940\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:    0.16217 Validation Accuracy: 0.70060\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:    0.11243 Validation Accuracy: 0.68700\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:    0.14312 Validation Accuracy: 0.71420\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:    0.09406 Validation Accuracy: 0.72440\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:    0.15357 Validation Accuracy: 0.66840\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:    0.14382 Validation Accuracy: 0.70860\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:    0.07769 Validation Accuracy: 0.69160\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:    0.11548 Validation Accuracy: 0.71840\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:    0.08269 Validation Accuracy: 0.71840\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:    0.10898 Validation Accuracy: 0.70060\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:    0.11423 Validation Accuracy: 0.68820\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:    0.10160 Validation Accuracy: 0.68300\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:    0.09356 Validation Accuracy: 0.71500\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:    0.05775 Validation Accuracy: 0.71860\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:    0.11816 Validation Accuracy: 0.69420\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:    0.10220 Validation Accuracy: 0.70100\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:    0.06729 Validation Accuracy: 0.69500\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:    0.08110 Validation Accuracy: 0.72120\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:    0.05654 Validation Accuracy: 0.72140\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:    0.08328 Validation Accuracy: 0.70500\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:    0.11834 Validation Accuracy: 0.70260\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:    0.03932 Validation Accuracy: 0.70760\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:    0.08784 Validation Accuracy: 0.71220\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:    0.04997 Validation Accuracy: 0.71760\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:    0.07083 Validation Accuracy: 0.69740\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:    0.11442 Validation Accuracy: 0.70400\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:    0.05947 Validation Accuracy: 0.71100\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:    0.07459 Validation Accuracy: 0.71380\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:    0.05563 Validation Accuracy: 0.71280\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:    0.08765 Validation Accuracy: 0.70040\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:    0.08741 Validation Accuracy: 0.71120\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:    0.05118 Validation Accuracy: 0.71480\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:    0.06337 Validation Accuracy: 0.70960\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:    0.04774 Validation Accuracy: 0.69780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, CIFAR-10 Batch 1:  Loss:    0.06561 Validation Accuracy: 0.70880\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:    0.09787 Validation Accuracy: 0.70780\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:    0.04033 Validation Accuracy: 0.72200\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:    0.07569 Validation Accuracy: 0.70360\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:    0.03766 Validation Accuracy: 0.70440\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:    0.05026 Validation Accuracy: 0.71340\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:    0.08039 Validation Accuracy: 0.71380\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:    0.02807 Validation Accuracy: 0.71860\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:    0.05486 Validation Accuracy: 0.70980\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:    0.02989 Validation Accuracy: 0.70280\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:    0.04775 Validation Accuracy: 0.71820\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:    0.07453 Validation Accuracy: 0.71920\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:    0.03176 Validation Accuracy: 0.71540\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:    0.04932 Validation Accuracy: 0.71060\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:    0.02854 Validation Accuracy: 0.71560\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:    0.05034 Validation Accuracy: 0.70780\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:    0.05072 Validation Accuracy: 0.71340\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:    0.03334 Validation Accuracy: 0.71740\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:    0.05303 Validation Accuracy: 0.70100\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:    0.02951 Validation Accuracy: 0.70220\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:    0.04183 Validation Accuracy: 0.70760\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:    0.05658 Validation Accuracy: 0.68880\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:    0.02442 Validation Accuracy: 0.72420\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:    0.03329 Validation Accuracy: 0.69900\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:    0.03256 Validation Accuracy: 0.68800\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:    0.03889 Validation Accuracy: 0.71640\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:    0.03545 Validation Accuracy: 0.70720\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:    0.02322 Validation Accuracy: 0.72160\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:    0.03956 Validation Accuracy: 0.69660\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:    0.02737 Validation Accuracy: 0.70320\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:    0.02465 Validation Accuracy: 0.71260\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:    0.03076 Validation Accuracy: 0.70100\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:    0.02749 Validation Accuracy: 0.70580\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:    0.05555 Validation Accuracy: 0.70820\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:    0.02988 Validation Accuracy: 0.69000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:    0.03593 Validation Accuracy: 0.71200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:    0.03737 Validation Accuracy: 0.69780\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:    0.01911 Validation Accuracy: 0.72060\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:    0.02172 Validation Accuracy: 0.70820\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:    0.01934 Validation Accuracy: 0.70060\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:    0.02444 Validation Accuracy: 0.71040\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:    0.03332 Validation Accuracy: 0.68980\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:    0.03033 Validation Accuracy: 0.71500\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:    0.02026 Validation Accuracy: 0.70640\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:    0.02500 Validation Accuracy: 0.70760\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:    0.02477 Validation Accuracy: 0.70720\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:    0.02405 Validation Accuracy: 0.70120\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:    0.02850 Validation Accuracy: 0.69880\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:    0.03243 Validation Accuracy: 0.71500\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:    0.01651 Validation Accuracy: 0.70960\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:    0.02953 Validation Accuracy: 0.70820\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:    0.02405 Validation Accuracy: 0.70800\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:    0.02118 Validation Accuracy: 0.71840\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:    0.02883 Validation Accuracy: 0.70460\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:    0.01425 Validation Accuracy: 0.71240\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:    0.03182 Validation Accuracy: 0.70300\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:    0.03404 Validation Accuracy: 0.70740\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:    0.02236 Validation Accuracy: 0.70400\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:    0.01601 Validation Accuracy: 0.70660\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:    0.01959 Validation Accuracy: 0.70580\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:    0.02213 Validation Accuracy: 0.70820\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:    0.02630 Validation Accuracy: 0.69080\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:    0.01432 Validation Accuracy: 0.72280\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:    0.03158 Validation Accuracy: 0.71240\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:    0.03301 Validation Accuracy: 0.70300\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:    0.02927 Validation Accuracy: 0.70920\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:    0.02531 Validation Accuracy: 0.69040\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:    0.01764 Validation Accuracy: 0.70820\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:    0.02156 Validation Accuracy: 0.71140\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:    0.02407 Validation Accuracy: 0.71040\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:    0.04271 Validation Accuracy: 0.68700\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:    0.02575 Validation Accuracy: 0.70060\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:    0.01700 Validation Accuracy: 0.71380\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:    0.02096 Validation Accuracy: 0.70400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:    0.00714 Validation Accuracy: 0.70880\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:    0.02651 Validation Accuracy: 0.68740\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:    0.04235 Validation Accuracy: 0.71200\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:    0.01457 Validation Accuracy: 0.71980\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:    0.01729 Validation Accuracy: 0.70460\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:    0.01258 Validation Accuracy: 0.70620\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:    0.01853 Validation Accuracy: 0.68840\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:    0.02191 Validation Accuracy: 0.69460\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:    0.02172 Validation Accuracy: 0.71480\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:    0.02069 Validation Accuracy: 0.70880\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:    0.01159 Validation Accuracy: 0.68900\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:    0.01424 Validation Accuracy: 0.70500\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:    0.03002 Validation Accuracy: 0.69260\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:    0.01184 Validation Accuracy: 0.72040\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:    0.01938 Validation Accuracy: 0.70740\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:    0.00761 Validation Accuracy: 0.70660\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:    0.02046 Validation Accuracy: 0.70020\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:    0.02036 Validation Accuracy: 0.68900\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:    0.01739 Validation Accuracy: 0.71860\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:    0.02846 Validation Accuracy: 0.70520\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:    0.01027 Validation Accuracy: 0.70880\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:    0.01677 Validation Accuracy: 0.70160\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:    0.01380 Validation Accuracy: 0.70500\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:    0.02100 Validation Accuracy: 0.71620\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:    0.01912 Validation Accuracy: 0.69540\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:    0.01383 Validation Accuracy: 0.70360\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:    0.01293 Validation Accuracy: 0.69480\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:    0.01477 Validation Accuracy: 0.70860\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:    0.00994 Validation Accuracy: 0.71640\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:    0.01526 Validation Accuracy: 0.68620\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:    0.01006 Validation Accuracy: 0.70820\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:    0.02271 Validation Accuracy: 0.69900\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:    0.00846 Validation Accuracy: 0.69880\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:    0.02065 Validation Accuracy: 0.71140\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:    0.01318 Validation Accuracy: 0.69520\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:    0.01847 Validation Accuracy: 0.70840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, CIFAR-10 Batch 1:  Loss:    0.01456 Validation Accuracy: 0.70620\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:    0.00866 Validation Accuracy: 0.70720\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:    0.01905 Validation Accuracy: 0.71980\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:    0.01199 Validation Accuracy: 0.69060\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:    0.01041 Validation Accuracy: 0.70880\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:    0.01024 Validation Accuracy: 0.70400\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:    0.01458 Validation Accuracy: 0.70420\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:    0.01016 Validation Accuracy: 0.71640\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:    0.02143 Validation Accuracy: 0.69520\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:    0.00544 Validation Accuracy: 0.72540\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:    0.00946 Validation Accuracy: 0.70280\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:    0.00559 Validation Accuracy: 0.70520\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:    0.01011 Validation Accuracy: 0.71540\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:    0.00647 Validation Accuracy: 0.69880\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:    0.00708 Validation Accuracy: 0.71700\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:    0.00916 Validation Accuracy: 0.69420\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:    0.00720 Validation Accuracy: 0.70660\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:    0.00614 Validation Accuracy: 0.71080\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:    0.00737 Validation Accuracy: 0.69480\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:    0.00530 Validation Accuracy: 0.70860\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:    0.00827 Validation Accuracy: 0.71760\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:    0.00311 Validation Accuracy: 0.71400\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:    0.00473 Validation Accuracy: 0.71320\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:    0.00897 Validation Accuracy: 0.70000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:    0.00585 Validation Accuracy: 0.70700\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:    0.00600 Validation Accuracy: 0.70340\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:    0.00842 Validation Accuracy: 0.70840\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:    0.00653 Validation Accuracy: 0.70680\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:    0.01208 Validation Accuracy: 0.70720\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:    0.01157 Validation Accuracy: 0.71040\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:    0.00580 Validation Accuracy: 0.70560\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:    0.01489 Validation Accuracy: 0.70420\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:    0.00526 Validation Accuracy: 0.71900\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:    0.01353 Validation Accuracy: 0.69080\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:    0.01505 Validation Accuracy: 0.71260\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:    0.00559 Validation Accuracy: 0.69560\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:    0.00631 Validation Accuracy: 0.70480\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:    0.00830 Validation Accuracy: 0.71660\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:    0.02089 Validation Accuracy: 0.68340\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:    0.00896 Validation Accuracy: 0.72100\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:    0.00626 Validation Accuracy: 0.70360\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:    0.00566 Validation Accuracy: 0.70860\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:    0.00755 Validation Accuracy: 0.71920\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:    0.02031 Validation Accuracy: 0.68200\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:    0.01055 Validation Accuracy: 0.70720\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:    0.01777 Validation Accuracy: 0.69460\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:    0.00579 Validation Accuracy: 0.70480\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:    0.01343 Validation Accuracy: 0.70540\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:    0.01975 Validation Accuracy: 0.68860\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:    0.00873 Validation Accuracy: 0.70560\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:    0.00571 Validation Accuracy: 0.69820\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:    0.00842 Validation Accuracy: 0.70340\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:    0.00761 Validation Accuracy: 0.71400\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:    0.01309 Validation Accuracy: 0.68720\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:    0.00884 Validation Accuracy: 0.70720\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:    0.00733 Validation Accuracy: 0.69740\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:    0.02474 Validation Accuracy: 0.70480\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:    0.00796 Validation Accuracy: 0.71660\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:    0.01222 Validation Accuracy: 0.69120\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:    0.00941 Validation Accuracy: 0.70100\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:    0.01075 Validation Accuracy: 0.69900\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:    0.00657 Validation Accuracy: 0.69820\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:    0.00555 Validation Accuracy: 0.71680\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:    0.00799 Validation Accuracy: 0.70520\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:    0.00850 Validation Accuracy: 0.70160\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:    0.00556 Validation Accuracy: 0.70980\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:    0.00387 Validation Accuracy: 0.71280\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:    0.00966 Validation Accuracy: 0.71520\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:    0.00810 Validation Accuracy: 0.70220\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:    0.00853 Validation Accuracy: 0.70200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:    0.00887 Validation Accuracy: 0.71060\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:    0.00874 Validation Accuracy: 0.70720\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:    0.00304 Validation Accuracy: 0.72220\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:    0.00810 Validation Accuracy: 0.69600\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:    0.00717 Validation Accuracy: 0.69740\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:    0.00962 Validation Accuracy: 0.69500\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:    0.00176 Validation Accuracy: 0.70720\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:    0.00276 Validation Accuracy: 0.72300\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:    0.01412 Validation Accuracy: 0.70000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:    0.00305 Validation Accuracy: 0.70440\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:    0.00405 Validation Accuracy: 0.69360\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:    0.01359 Validation Accuracy: 0.70380\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:    0.00802 Validation Accuracy: 0.71360\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:    0.00821 Validation Accuracy: 0.69900\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:    0.00283 Validation Accuracy: 0.70440\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:    0.01719 Validation Accuracy: 0.68580\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:    0.00398 Validation Accuracy: 0.70400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:    0.00228 Validation Accuracy: 0.71400\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:    0.00939 Validation Accuracy: 0.69940\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:    0.00374 Validation Accuracy: 0.71020\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:    0.00944 Validation Accuracy: 0.70400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:    0.00226 Validation Accuracy: 0.70020\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:    0.00293 Validation Accuracy: 0.71600\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:    0.00574 Validation Accuracy: 0.69200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:    0.00655 Validation Accuracy: 0.70040\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:    0.01135 Validation Accuracy: 0.69900\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:    0.00502 Validation Accuracy: 0.69800\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:    0.00243 Validation Accuracy: 0.71560\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:    0.00708 Validation Accuracy: 0.68480\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:    0.00560 Validation Accuracy: 0.70480\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:    0.00494 Validation Accuracy: 0.69800\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:    0.00131 Validation Accuracy: 0.70560\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:    0.00105 Validation Accuracy: 0.71960\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:    0.00406 Validation Accuracy: 0.69360\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:    0.00611 Validation Accuracy: 0.69900\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:    0.00861 Validation Accuracy: 0.69320\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:    0.00845 Validation Accuracy: 0.69060\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:    0.00697 Validation Accuracy: 0.71440\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:    0.00330 Validation Accuracy: 0.70060\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:    0.00243 Validation Accuracy: 0.69820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67, CIFAR-10 Batch 1:  Loss:    0.00548 Validation Accuracy: 0.70860\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:    0.00386 Validation Accuracy: 0.69000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:    0.00185 Validation Accuracy: 0.71020\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:    0.00771 Validation Accuracy: 0.70680\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:    0.00399 Validation Accuracy: 0.70600\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:    0.00927 Validation Accuracy: 0.70300\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:    0.00700 Validation Accuracy: 0.69300\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:    0.00766 Validation Accuracy: 0.71120\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:    0.00353 Validation Accuracy: 0.70520\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:    0.00891 Validation Accuracy: 0.70380\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:    0.00358 Validation Accuracy: 0.71600\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:    0.00256 Validation Accuracy: 0.69780\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:    0.01526 Validation Accuracy: 0.70940\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:    0.00482 Validation Accuracy: 0.69620\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:    0.00317 Validation Accuracy: 0.70260\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:    0.00849 Validation Accuracy: 0.70300\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:    0.00282 Validation Accuracy: 0.69340\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:    0.00154 Validation Accuracy: 0.72020\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:    0.00499 Validation Accuracy: 0.69000\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:    0.00449 Validation Accuracy: 0.71340\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:    0.00808 Validation Accuracy: 0.69600\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:    0.01337 Validation Accuracy: 0.69800\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:    0.01304 Validation Accuracy: 0.71700\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:    0.01763 Validation Accuracy: 0.71380\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:    0.00398 Validation Accuracy: 0.70820\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:    0.00432 Validation Accuracy: 0.69960\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:    0.00718 Validation Accuracy: 0.69580\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:    0.00209 Validation Accuracy: 0.71480\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:    0.00893 Validation Accuracy: 0.70760\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:    0.00337 Validation Accuracy: 0.71620\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:    0.00323 Validation Accuracy: 0.71380\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:    0.00174 Validation Accuracy: 0.70060\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:    0.00224 Validation Accuracy: 0.71140\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:    0.00562 Validation Accuracy: 0.70180\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:    0.00124 Validation Accuracy: 0.71900\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:    0.00484 Validation Accuracy: 0.70540\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:    0.00306 Validation Accuracy: 0.69560\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:    0.00376 Validation Accuracy: 0.71420\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:    0.00288 Validation Accuracy: 0.70040\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:    0.00307 Validation Accuracy: 0.72500\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:    0.00459 Validation Accuracy: 0.71600\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:    0.00295 Validation Accuracy: 0.69440\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:    0.00565 Validation Accuracy: 0.71500\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:    0.00430 Validation Accuracy: 0.70280\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:    0.00116 Validation Accuracy: 0.71640\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:    0.00487 Validation Accuracy: 0.71500\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:    0.00106 Validation Accuracy: 0.70740\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:    0.00109 Validation Accuracy: 0.71240\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:    0.00399 Validation Accuracy: 0.69720\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:    0.00378 Validation Accuracy: 0.71660\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:    0.00127 Validation Accuracy: 0.71240\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:    0.00540 Validation Accuracy: 0.70860\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:    0.00202 Validation Accuracy: 0.71660\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:    0.00323 Validation Accuracy: 0.69800\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:    0.00169 Validation Accuracy: 0.71680\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:    0.01007 Validation Accuracy: 0.70920\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:    0.00225 Validation Accuracy: 0.70600\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:    0.00055 Validation Accuracy: 0.70640\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:    0.00320 Validation Accuracy: 0.69860\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:    0.00102 Validation Accuracy: 0.70980\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:    0.00239 Validation Accuracy: 0.71940\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:    0.00189 Validation Accuracy: 0.70560\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:    0.00070 Validation Accuracy: 0.72040\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:    0.00186 Validation Accuracy: 0.69260\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:    0.00098 Validation Accuracy: 0.72620\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:    0.00376 Validation Accuracy: 0.71280\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:    0.00116 Validation Accuracy: 0.70020\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:    0.00147 Validation Accuracy: 0.71340\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:    0.00356 Validation Accuracy: 0.69820\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:    0.00138 Validation Accuracy: 0.70960\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:    0.00551 Validation Accuracy: 0.72100\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:    0.00179 Validation Accuracy: 0.71260\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:    0.00053 Validation Accuracy: 0.71400\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:    0.00508 Validation Accuracy: 0.69740\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:    0.00105 Validation Accuracy: 0.71580\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:    0.00478 Validation Accuracy: 0.71140\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:    0.00093 Validation Accuracy: 0.70720\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:    0.00156 Validation Accuracy: 0.72040\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:    0.00297 Validation Accuracy: 0.70340\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:    0.00215 Validation Accuracy: 0.70480\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:    0.00271 Validation Accuracy: 0.71800\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:    0.00064 Validation Accuracy: 0.71280\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:    0.00027 Validation Accuracy: 0.71820\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:    0.00509 Validation Accuracy: 0.70240\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:    0.00196 Validation Accuracy: 0.70580\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:    0.00451 Validation Accuracy: 0.71220\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:    0.00119 Validation Accuracy: 0.70740\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:    0.00139 Validation Accuracy: 0.71420\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:    0.00530 Validation Accuracy: 0.69960\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:    0.00531 Validation Accuracy: 0.69620\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:    0.00182 Validation Accuracy: 0.72000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:    0.00370 Validation Accuracy: 0.71420\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:    0.00030 Validation Accuracy: 0.71540\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:    0.00317 Validation Accuracy: 0.69440\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:    0.00213 Validation Accuracy: 0.71400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:    0.00256 Validation Accuracy: 0.71840\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:    0.00099 Validation Accuracy: 0.72060\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:    0.00057 Validation Accuracy: 0.71820\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:    0.00415 Validation Accuracy: 0.69140\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:    0.00064 Validation Accuracy: 0.71400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:    0.00192 Validation Accuracy: 0.71580\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:    0.00214 Validation Accuracy: 0.70600\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:    0.00067 Validation Accuracy: 0.71680\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:    0.00509 Validation Accuracy: 0.69440\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:    0.00325 Validation Accuracy: 0.70880\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:    0.00353 Validation Accuracy: 0.72140\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:    0.00178 Validation Accuracy: 0.71140\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:    0.00034 Validation Accuracy: 0.72040\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:    0.00345 Validation Accuracy: 0.70360\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:    0.00187 Validation Accuracy: 0.70940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89, CIFAR-10 Batch 1:  Loss:    0.00325 Validation Accuracy: 0.72080\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:    0.00120 Validation Accuracy: 0.71260\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:    0.00120 Validation Accuracy: 0.71980\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:    0.00345 Validation Accuracy: 0.69780\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:    0.01367 Validation Accuracy: 0.71440\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:    0.00523 Validation Accuracy: 0.71780\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:    0.00308 Validation Accuracy: 0.71420\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:    0.00041 Validation Accuracy: 0.71520\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:    0.00572 Validation Accuracy: 0.69620\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:    0.00236 Validation Accuracy: 0.70780\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:    0.00392 Validation Accuracy: 0.72120\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:    0.00104 Validation Accuracy: 0.71640\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:    0.00035 Validation Accuracy: 0.72300\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:    0.00125 Validation Accuracy: 0.70020\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:    0.00116 Validation Accuracy: 0.71280\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:    0.00151 Validation Accuracy: 0.72320\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:    0.00275 Validation Accuracy: 0.71800\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:    0.00131 Validation Accuracy: 0.71960\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:    0.00067 Validation Accuracy: 0.71160\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:    0.00106 Validation Accuracy: 0.72360\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:    0.00088 Validation Accuracy: 0.72700\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:    0.00144 Validation Accuracy: 0.71700\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:    0.00133 Validation Accuracy: 0.71620\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:    0.00946 Validation Accuracy: 0.70600\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:    0.00087 Validation Accuracy: 0.71820\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:    0.00392 Validation Accuracy: 0.71860\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:    0.00143 Validation Accuracy: 0.72480\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:    0.00113 Validation Accuracy: 0.71520\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:    0.00405 Validation Accuracy: 0.70460\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:    0.00336 Validation Accuracy: 0.70780\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:    0.00165 Validation Accuracy: 0.71760\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:    0.00089 Validation Accuracy: 0.71180\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:    0.00044 Validation Accuracy: 0.71500\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:    0.00163 Validation Accuracy: 0.70840\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:    0.00085 Validation Accuracy: 0.70840\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:    0.00064 Validation Accuracy: 0.72320\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:    0.00157 Validation Accuracy: 0.71700\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:    0.00017 Validation Accuracy: 0.71600\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:    0.00925 Validation Accuracy: 0.71120\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:    0.00060 Validation Accuracy: 0.71520\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:    0.00193 Validation Accuracy: 0.72300\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:    0.00155 Validation Accuracy: 0.70980\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:    0.00037 Validation Accuracy: 0.71740\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:    0.00387 Validation Accuracy: 0.70900\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:    0.00046 Validation Accuracy: 0.72080\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:    0.00103 Validation Accuracy: 0.72000\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:    0.00073 Validation Accuracy: 0.71980\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:    0.00013 Validation Accuracy: 0.72180\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:    0.00170 Validation Accuracy: 0.69520\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:    0.00114 Validation Accuracy: 0.70940\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:    0.00081 Validation Accuracy: 0.72460\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:    0.00032 Validation Accuracy: 0.71360\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:    0.00025 Validation Accuracy: 0.71180\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:    0.00294 Validation Accuracy: 0.70380\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:    0.00076 Validation Accuracy: 0.71140\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:    0.00161 Validation Accuracy: 0.72120\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:    0.00675 Validation Accuracy: 0.71220\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:    0.00026 Validation Accuracy: 0.71580\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:    0.00109 Validation Accuracy: 0.70680\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:    0.00214 Validation Accuracy: 0.71460\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.7104896496815286\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArsAAAJ/CAYAAAB4GhsgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4b329dce80>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
