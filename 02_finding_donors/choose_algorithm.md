# 算法分析和学习

![machine_learning_map](http://scikit-learn.org/stable/_static/ml_map.png)

| 问题类型 | 支持的方法                            |
| ---- | -------------------------------- |
| 二分类  | 线性SVMs、逻辑回归、决策树、随机森林、梯度增强树、朴素贝叶斯 |
| 多分类  | 逻辑回归、决策树、随机森林、朴素贝叶斯              |
| 回归   | 线性最小二乘、决策树、随机森林、梯度增强树、保序回归       |



## 高斯朴素贝叶斯（GaussianNB）

[朴素贝叶斯分类器wiki](https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8)

适用于文本数据处理，朴素贝叶斯架设特征之间朴素独立，互不联系，采用贝叶斯定理为基础对数据进行简单概率分类。

- **优点：**简单快捷，需要的数据量不大，可以处理多分类问题。
- **缺点：**结果准确性可能不高，特征强独立假设在大幅提高算法效率的同时也在一定程度上影响了算法的效果。

## 决策树（Decision Tree）

**决策树的优点：**

- 1 决策树易于理解和解释；
- 2 能够同时处理数据型和类别型属性；
- 3 决策树是一个白盒模型，给定一个观察模型，很容易推出相应的逻辑表达式；
- 4 在相对较短的时间内能够对大型数据作出效果良好的结果；
- 5 比较适合处理有缺失属性值的样本。

**决策树的缺点：**

- 1 对那些各类别数据量不一致的数据，在决策树种，信息增益的结果偏向那些具有更多数值的特征；
- 2 容易过拟合；
- 3 忽略了数据集中属性之间的相关性。

## 随机森林

随机森林是将bagging和决策树整合而成的机器学习方法，可以解决决策树的过拟合问题，在进行决策时，对每个决策树的结果进行加权表决来避免过拟合。

**随机森林的优点有：**

- 对于很多种资料，它可以产生高准确度的分类器。
- 它可以处理大量的输入变数。
- 它可以在决定类别时，评估变数的重要性。
- 在建造森林时，它可以在内部对于一般化后的误差产生不偏差的估计。
- 它包含一个好方法可以估计遗失的资料，并且，如果有很大一部分的资料遗失，仍可以维持准确度。
- 它提供一个实验方法，可以去侦测variable interactions。
- 对于不平衡的分类资料集来说，它可以平衡误差。
- 它计算各例中的亲近度，对于[数据挖掘](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98)、侦测[离群点](https://zh.wikipedia.org/w/index.php?title=%E9%9B%A2%E7%BE%A4%E9%BB%9E&action=edit&redlink=1)（outlier）和将资料视觉化非常有用。
- 使用上述。它可被延伸应用在未标记的资料上，这类资料通常是使用[非监督式](https://zh.wikipedia.org/wiki/%E9%9D%9E%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92)[聚类](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E8%81%9A%E7%B1%BB)。也可侦测偏离者和观看资料。
- 学习过程是很快速的。

**缺点：**

- 随机森林已经被证明在某些**噪音较大**的分类或回归问题上会过拟
- 对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的。

## KNN

